{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "big-mart-sales-dataset\n",
      "bigmartsale\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "#print(os.listdir(\"../input/\"))\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input/\"]).decode(\"utf8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastai==0.7.0\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/6d/9d0d6e17a78b0598d5e8c49a0d03ffc7ff265ae62eca3e2345fab14edb9b/fastai-0.7.0-py3-none-any.whl (112kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 5.8MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: Pygments in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (2.2.0)\r\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (2.2.0)\r\n",
      "Requirement already satisfied: html5lib in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (1.0.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (1.16.2)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (4.3.0)\r\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (2.1.3)\r\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (2.6.0)\r\n",
      "Requirement already satisfied: jupyter in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (1.0.0)\r\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (3.0.3)\r\n",
      "Requirement already satisfied: cycler in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.10.0)\r\n",
      "Requirement already satisfied: pandas-summary in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.0.6)\r\n",
      "Requirement already satisfied: traitlets in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (4.3.2)\r\n",
      "Requirement already satisfied: torchtext in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.3.1)\r\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.2.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.1.7)\r\n",
      "Requirement already satisfied: simplegeneric in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.8.1)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (2019.3.9)\r\n",
      "Requirement already satisfied: Jinja2 in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (2.10)\r\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.5.1)\r\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.3.1)\r\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (4.8.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (4.31.1)\r\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (6.4.0)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.2.2)\r\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (2018.4)\r\n",
      "Requirement already satisfied: feather-format in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.4.0)\r\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.8.4)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.7.4)\r\n",
      "Requirement already satisfied: bcolz in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (1.2.1)\r\n",
      "Requirement already satisfied: jedi in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.12.0)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.23.4)\r\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (4.0.0.21)\r\n",
      "Requirement already satisfied: tornado in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (5.0.2)\r\n",
      "Requirement already satisfied: MarkupSafe in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (1.0)\r\n",
      "Requirement already satisfied: isoweek in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (1.3.3)\r\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (3.12)\r\n",
      "Requirement already satisfied: sklearn-pandas in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (1.8.0)\r\n",
      "Requirement already satisfied: plotnine in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.4.0)\r\n",
      "Collecting torch<0.4 (from fastai==0.7.0)\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/a5/e8b50b55b1abac9f1e3346c4242f1e42a82d368a8442cbd50c532922f6c4/torch-0.3.1-cp36-cp36m-manylinux1_x86_64.whl (496.4MB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 496.4MB 61kB/s \r\n",
      "\u001b[?25hRequirement already satisfied: ptyprocess in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.5.2)\r\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (7.2.1)\r\n",
      "Requirement already satisfied: pyzmq in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (17.0.0)\r\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.2.3)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (1.1.0)\r\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (2.6.0)\r\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (0.9.0)\r\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (5.1.0)\r\n",
      "Requirement already satisfied: widgetsnbextension in /opt/conda/lib/python3.6/site-packages (from fastai==0.7.0) (3.2.1)\r\n",
      "Requirement already satisfied: six>=1.9 in /opt/conda/lib/python3.6/site-packages (from html5lib->fastai==0.7.0) (1.12.0)\r\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.6/site-packages (from jupyter->fastai==0.7.0) (5.5.0)\r\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.6/site-packages (from jupyter->fastai==0.7.0) (4.3.1)\r\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.6/site-packages (from jupyter->fastai==0.7.0) (5.2.0)\r\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.6/site-packages (from jupyter->fastai==0.7.0) (5.3.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->fastai==0.7.0) (1.0.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from torchtext->fastai==0.7.0) (2.21.0)\r\n",
      "Requirement already satisfied: jupyter_client in /opt/conda/lib/python3.6/site-packages (from ipykernel->fastai==0.7.0) (5.2.3)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython->fastai==0.7.0) (0.1.0)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.6/site-packages (from ipython->fastai==0.7.0) (39.1.0)\r\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.6/site-packages (from ipython->fastai==0.7.0) (4.5.0)\r\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.15 in /opt/conda/lib/python3.6/site-packages (from ipython->fastai==0.7.0) (1.0.15)\r\n",
      "Requirement already satisfied: pyarrow>=0.4.0 in /opt/conda/lib/python3.6/site-packages (from feather-format->fastai==0.7.0) (0.10.0)\r\n",
      "Requirement already satisfied: parso>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from jedi->fastai==0.7.0) (0.2.0)\r\n",
      "Requirement already satisfied: scikit-learn>=0.15.0 in /opt/conda/lib/python3.6/site-packages (from sklearn-pandas->fastai==0.7.0) (0.20.3)\r\n",
      "Requirement already satisfied: mizani>=0.4.5 in /opt/conda/lib/python3.6/site-packages (from plotnine->fastai==0.7.0) (0.5.4)\r\n",
      "Requirement already satisfied: geopandas>=0.3.0 in /opt/conda/lib/python3.6/site-packages (from plotnine->fastai==0.7.0) (0.4.1)\r\n",
      "Requirement already satisfied: descartes>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from plotnine->fastai==0.7.0) (1.1.0)\r\n",
      "Requirement already satisfied: statsmodels>=0.8.0 in /opt/conda/lib/python3.6/site-packages (from plotnine->fastai==0.7.0) (0.9.0)\r\n",
      "Requirement already satisfied: patsy>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from plotnine->fastai==0.7.0) (0.5.0)\r\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets->fastai==0.7.0) (4.4.0)\r\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter->fastai==0.7.0) (0.8.1)\r\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter->fastai==0.7.0) (1.5.0)\r\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in /opt/conda/lib/python3.6/site-packages (from notebook->jupyter->fastai==0.7.0) (4.4.0)\r\n",
      "Requirement already satisfied: mistune>=0.7.4 in /opt/conda/lib/python3.6/site-packages (from nbconvert->jupyter->fastai==0.7.0) (0.8.3)\r\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.6/site-packages (from nbconvert->jupyter->fastai==0.7.0) (1.4.2)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->torchtext->fastai==0.7.0) (3.0.4)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->torchtext->fastai==0.7.0) (2.6)\r\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->torchtext->fastai==0.7.0) (1.22)\r\n",
      "Requirement already satisfied: palettable in /opt/conda/lib/python3.6/site-packages (from mizani>=0.4.5->plotnine->fastai==0.7.0) (3.1.1)\r\n",
      "Requirement already satisfied: fiona in /opt/conda/lib/python3.6/site-packages (from geopandas>=0.3.0->plotnine->fastai==0.7.0) (1.8.6)\r\n",
      "Requirement already satisfied: shapely in /opt/conda/lib/python3.6/site-packages (from geopandas>=0.3.0->plotnine->fastai==0.7.0) (1.6.4.post2)\r\n",
      "Requirement already satisfied: pyproj in /opt/conda/lib/python3.6/site-packages (from geopandas>=0.3.0->plotnine->fastai==0.7.0) (2.1.3)\r\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.6/site-packages (from fiona->geopandas>=0.3.0->plotnine->fastai==0.7.0) (1.1.1)\r\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.6/site-packages (from fiona->geopandas>=0.3.0->plotnine->fastai==0.7.0) (2.3.2)\r\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.6/site-packages (from fiona->geopandas>=0.3.0->plotnine->fastai==0.7.0) (0.5.0)\r\n",
      "Requirement already satisfied: attrs>=17 in /opt/conda/lib/python3.6/site-packages (from fiona->geopandas>=0.3.0->plotnine->fastai==0.7.0) (18.1.0)\r\n",
      "Requirement already satisfied: click<8,>=4.0 in /opt/conda/lib/python3.6/site-packages (from fiona->geopandas>=0.3.0->plotnine->fastai==0.7.0) (7.0)\r\n",
      "Installing collected packages: torch, fastai\r\n",
      "  Found existing installation: torch 1.0.1.post2\r\n",
      "    Uninstalling torch-1.0.1.post2:\r\n",
      "      Successfully uninstalled torch-1.0.1.post2\r\n",
      "  Found existing installation: fastai 1.0.51\r\n",
      "    Uninstalling fastai-1.0.51:\r\n",
      "      Successfully uninstalled fastai-1.0.51\r\n",
      "Successfully installed fastai-0.7.0 torch-0.3.1\r\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "!pip install fastai==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "\n",
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../input/bigmartsale\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SampleSubmission.csv  Test.csv\tTrain.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls  {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(f'{PATH}/Train.csv', low_memory=False, \n",
    "                    )\n",
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility',\n",
       "       'Item_Type', 'Item_MRP', 'Outlet_Identifier',\n",
       "       'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',\n",
       "       'Outlet_Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(f'{PATH}/Test.csv', low_memory=False, \n",
    "                     )\n",
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility',\n",
       "       'Item_Type', 'Item_MRP', 'Outlet_Identifier',\n",
       "       'Outlet_Establishment_Year', 'Outlet_Size', 'Outlet_Location_Type',\n",
       "       'Outlet_Type', 'Item_Outlet_Sales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_Identifier', 'Outlet_Identifier', 'Item_Outlet_Sales'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sub = pd.read_csv(f'{PATH}/SampleSubmission.csv', low_memory=False)\n",
    "sample_sub.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8518</th>\n",
       "      <th>8519</th>\n",
       "      <th>8520</th>\n",
       "      <th>8521</th>\n",
       "      <th>8522</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Item_Identifier</th>\n",
       "      <td>FDF22</td>\n",
       "      <td>FDS36</td>\n",
       "      <td>NCJ29</td>\n",
       "      <td>FDN46</td>\n",
       "      <td>DRG01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Weight</th>\n",
       "      <td>6.865</td>\n",
       "      <td>8.38</td>\n",
       "      <td>10.6</td>\n",
       "      <td>7.21</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <td>Low Fat</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Low Fat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Visibility</th>\n",
       "      <td>0.0567834</td>\n",
       "      <td>0.0469824</td>\n",
       "      <td>0.0351863</td>\n",
       "      <td>0.145221</td>\n",
       "      <td>0.0448783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Type</th>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>Baking Goods</td>\n",
       "      <td>Health and Hygiene</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>Soft Drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_MRP</th>\n",
       "      <td>214.522</td>\n",
       "      <td>108.157</td>\n",
       "      <td>85.1224</td>\n",
       "      <td>103.133</td>\n",
       "      <td>75.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <td>OUT013</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>OUT035</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>OUT046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <td>1987</td>\n",
       "      <td>2002</td>\n",
       "      <td>2004</td>\n",
       "      <td>2009</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Size</th>\n",
       "      <td>High</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Small</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Tier 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Type</th>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <td>2778.38</td>\n",
       "      <td>549.285</td>\n",
       "      <td>1193.11</td>\n",
       "      <td>1845.6</td>\n",
       "      <td>765.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        8518               8519  \\\n",
       "Item_Identifier                        FDF22              FDS36   \n",
       "Item_Weight                            6.865               8.38   \n",
       "Item_Fat_Content                     Low Fat            Regular   \n",
       "Item_Visibility                    0.0567834          0.0469824   \n",
       "Item_Type                        Snack Foods       Baking Goods   \n",
       "Item_MRP                             214.522            108.157   \n",
       "Outlet_Identifier                     OUT013             OUT045   \n",
       "Outlet_Establishment_Year               1987               2002   \n",
       "Outlet_Size                             High                NaN   \n",
       "Outlet_Location_Type                  Tier 3             Tier 2   \n",
       "Outlet_Type                Supermarket Type1  Supermarket Type1   \n",
       "Item_Outlet_Sales                    2778.38            549.285   \n",
       "\n",
       "                                         8520               8521  \\\n",
       "Item_Identifier                         NCJ29              FDN46   \n",
       "Item_Weight                              10.6               7.21   \n",
       "Item_Fat_Content                      Low Fat            Regular   \n",
       "Item_Visibility                     0.0351863           0.145221   \n",
       "Item_Type                  Health and Hygiene        Snack Foods   \n",
       "Item_MRP                              85.1224            103.133   \n",
       "Outlet_Identifier                      OUT035             OUT018   \n",
       "Outlet_Establishment_Year                2004               2009   \n",
       "Outlet_Size                             Small             Medium   \n",
       "Outlet_Location_Type                   Tier 2             Tier 3   \n",
       "Outlet_Type                 Supermarket Type1  Supermarket Type2   \n",
       "Item_Outlet_Sales                     1193.11             1845.6   \n",
       "\n",
       "                                        8522  \n",
       "Item_Identifier                        DRG01  \n",
       "Item_Weight                             14.8  \n",
       "Item_Fat_Content                     Low Fat  \n",
       "Item_Visibility                    0.0448783  \n",
       "Item_Type                        Soft Drinks  \n",
       "Item_MRP                              75.467  \n",
       "Outlet_Identifier                     OUT046  \n",
       "Outlet_Establishment_Year               1997  \n",
       "Outlet_Size                            Small  \n",
       "Outlet_Location_Type                  Tier 1  \n",
       "Outlet_Type                Supermarket Type1  \n",
       "Item_Outlet_Sales                     765.67  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_all(df_raw.tail().T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this case Kaggle tells us what metric to use: RMSLE (root mean squared log error) between the actual and predicted auction prices. Therefore we take the log of the prices, so that RMSE will give us what we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_raw.dtypes)\n",
    "#print(df_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method extracts particular date fields from a complete datetime for the purpose of constructing categoricals. You should always consider this feature extraction step when working with date-time. Without expanding your date-time into these additional fields, you can't capture any trend/cyclical behavior as a function of time at any of these granularities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical variables are currently stored as strings, which is inefficient, and doesn't provide the numeric coding required for a random forest. Therefore we call train_cats to convert strings to pandas categories.Pandas categories store a numeric code for each category at the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Low Fat', 'reg', 'Regular', 'LF', 'low fat'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Item_Fat_Content'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_raw)):\n",
    "    if (df_raw['Item_Fat_Content'][i] == 'low fat'):\n",
    "        df_raw['Item_Fat_Content'][i]='Low Fat'\n",
    "    elif df_raw['Item_Fat_Content'][i] == 'LF':\n",
    "        df_raw['Item_Fat_Content'][i]='Low Fat'\n",
    "    elif df_raw['Item_Fat_Content'][i] == 'reg':\n",
    "        df_raw['Item_Fat_Content'][i]= 'Regular'\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_test)):\n",
    "    if (df_test['Item_Fat_Content'][i] == 'low fat'):\n",
    "        df_test['Item_Fat_Content'][i]='Low Fat'\n",
    "    elif df_test['Item_Fat_Content'][i] == 'LF':\n",
    "        df_test['Item_Fat_Content'][i]='Low Fat'\n",
    "    elif df_test['Item_Fat_Content'][i] == 'reg':\n",
    "        df_test['Item_Fat_Content'][i]= 'Regular'\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cats(df_raw)\n",
    "apply_cats(df_test,df_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, pandas will continue displaying the text categories, while treating them as numerical data internally. Optionally, we can replace the text categories with numbers, which will make this variable non-categorical, like so:.\n",
    "Note that only one variable is changed and remaining are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're still not quite done - for instance we have lots of missing values, which we can't pass directly to a random forest.\n",
    "\n",
    "Calculating the % of M.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Fat_Content             0.000000\n",
       "Item_Identifier              0.000000\n",
       "Item_MRP                     0.000000\n",
       "Item_Outlet_Sales            0.000000\n",
       "Item_Type                    0.000000\n",
       "Item_Visibility              0.000000\n",
       "Item_Weight                  0.171653\n",
       "Outlet_Establishment_Year    0.000000\n",
       "Outlet_Identifier            0.000000\n",
       "Outlet_Location_Type         0.000000\n",
       "Outlet_Size                  0.282764\n",
       "Outlet_Type                  0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_all(df_raw.isnull().sum().sort_index()/len(df_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll replace categories with their numeric codes, handle missing continuous values, and split the dependent variable into a separate variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y, nas = proc_df(df_raw, 'Item_Outlet_Sales')\n",
    "dft, y_t,nas_t = proc_df(df_test, na_dict = nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_vals(df,y):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(df, y, test_size=0.2)\n",
    "    return X_train, X_valid, y_train, y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = split_vals(df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    \"\"\"\n",
    "    Return: rmse of training vs actual\n",
    "            rmse on validation vs actual\n",
    "            r2 of training\n",
    "            r2 on validation\n",
    "    \"\"\"\n",
    "    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n",
    "                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Speeding things up -\n",
    "It turns out that one of the easiest ways to avoid over-fitting is also one of the best ways to speed up analysis: subsampling. Let's return to using our full dataset, so that we can demonstrate the impact of this technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea is this: rather than limit the total amount of data that our model can access, let's instead limit it to a different random subset per tree. That way, given enough trees, the model can still see all the data, but for each individual tree it'll be just as fast as if we had cut down to 20000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out-of-bag (OOB) score\n",
    "Is our validation set worse than our training set because we're over-fitting, or because the validation set is for a different time period, or a bit of both? With the existing information we've shown, we can't tell. However, random forests have a very clever trick called out-of-bag (OOB) error which can handle this (and more!)\n",
    "\n",
    "The idea is to calculate error on the training set, but only include the trees in the calculation of a row's error where that row was not included in training that tree. This allows us to see whether the model is over-fitting, without needing a separate validation set.\n",
    "\n",
    "This also has the benefit of allowing us to see whether our model generalizes, even if we only have a small amount of data so want to avoid separating some out to create a validation set.\n",
    "\n",
    "This is as simple as adding one more parameter to our model constructor. We print the OOB error last in our print_score function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot([metrics.r2_score(y_valid, np.mean(preds[:i+1], axis=0)) for i in range(30)]);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to reduce over-fitting is to grow our trees less deeply. We do this by specifying (with min_samples_leaf) that we require some minimum number of rows in every leaf node. This has two benefits:\n",
    "\n",
    "There are less decision rules for each leaf node; simpler models should generalize better\n",
    "The predictions are made by averaging more rows in the leaf node, resulting in less volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features=0.5, max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=11, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=-1,\n",
       "           oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"m = RandomForestRegressor(n_estimators=22, min_samples_leaf=3, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "m.fit(df, y)\n",
    "print(m.oob_score_)#submission2\n",
    "m = RandomForestRegressor(n_estimators=22, min_samples_leaf=5, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "m.fit(df, y)\n",
    "print(m.oob_score_)#submission3\n",
    "m = RandomForestRegressor(n_estimators=22, min_samples_leaf=5, max_features='log2', n_jobs=-1, oob_score=True)\n",
    "m.fit(df, y)\n",
    "print(m.oob_score_)\"\"\"#submission4\n",
    "\"\"\"m = RandomForestRegressor(n_estimators=80, min_samples_leaf=10, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "m.fit(df, y)\"\"\"#submission5 with grid search params score is 1157 rank 945\n",
    "m = RandomForestRegressor(n_estimators=90, min_samples_leaf=11, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(df, y)#submission 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = m.predict(dft)\n",
    "submission = pd.DataFrame({'Item_Identifier': df_test.Item_Identifier, 'Outlet_Identifier' : df_test.Outlet_Identifier,\n",
    "                           'Item_Outlet_Sales': predictions})\n",
    "submission.to_csv('submission6.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import RepeatedKFold, cross_val_score\\nfrom statistics import mean \\nkf = RepeatedKFold(n_splits=20, n_repeats=1, random_state=42) \\nclf = RandomForestRegressor(n_estimators=22, min_samples_leaf=5, max_features=\\'sqrt\\', n_jobs=-1)\\nlis = cross_val_score(clf, df, y, cv=kf, n_jobs=-1, scoring=\\'r2\\')\\nprint(\"mean validation r2 is: \"+ str(lis.mean()))\\nprint(\"the standard deviation is {} this mean how far is the each lis elements from lis.mean()\".format(lis.std()))\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#k-fold cross validation\n",
    "#for small dataset its better to use high value of K\n",
    "\"\"\"from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "from statistics import mean \n",
    "kf = RepeatedKFold(n_splits=20, n_repeats=1, random_state=42) \n",
    "clf = RandomForestRegressor(n_estimators=22, min_samples_leaf=5, max_features='sqrt', n_jobs=-1)\n",
    "lis = cross_val_score(clf, df, y, cv=kf, n_jobs=-1, scoring='r2')\n",
    "print(\"mean validation r2 is: \"+ str(lis.mean()))\n",
    "print(\"the standard deviation is {} this mean how far is the each lis elements from lis.mean()\".format(lis.std()))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before Grid Search we need to fit the model once\n",
    "#m = RandomForestRegressor(n_estimators=22, min_samples_leaf=5, max_features='sqrt', n_jobs=-1, oob_score=True)\n",
    "#m.fit(df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import GridSearchCV\\nparameters = [{\\'n_estimators\\': [40, 70,80, 90, 100], \\'min_samples_leaf\\': [7, 8, 9, 10, 11], \\'max_features\\': [\\'sqrt\\', \\'log2\\', 0.5]},\\n\\n             ]\\ngrid_search = GridSearchCV(estimator = m,\\n                           param_grid = parameters,\\n                           scoring = \\'r2\\',\\n                           cv = 10,\\n                           n_jobs = -1)\\ngrid_search = grid_search.fit(df, y)\\nbest_accuracy = grid_search.best_score_#given by mean of 10 folds\\nbest_parameters = grid_search.best_params_\\nprint (\"best accuracy is {}\".format(best_accuracy))\\nprint (\"best parametrs are {}\".format(best_parameters))'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the model after kFold cross validation by using Grid Search\n",
    "\"\"\"from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'n_estimators': [40, 70,80, 90, 100], 'min_samples_leaf': [7, 8, 9, 10, 11], 'max_features': ['sqrt', 'log2', 0.5]},\n",
    "\n",
    "             ]\n",
    "grid_search = GridSearchCV(estimator = m,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'r2',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(df, y)\n",
    "best_accuracy = grid_search.best_score_#given by mean of 10 folds\n",
    "best_parameters = grid_search.best_params_\n",
    "print (\"best accuracy is {}\".format(best_accuracy))\n",
    "print (\"best parametrs are {}\".format(best_parameters))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fi = rf_feat_importance(m, df); fi[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import accuracy_score\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xgb = xgboost.XGBRegressor(n_estimators=80, learning_rate=0.09, gamma=0, subsample=0.75,\\n                           colsample_bytree=1, max_depth=7)\\nxgb.fit(X_train,y_train)\\nprint_score(xgb)'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"xgb = xgboost.XGBRegressor(n_estimators=80, learning_rate=0.09, gamma=0, subsample=0.75,\n",
    "                           colsample_bytree=1, max_depth=7)\n",
    "xgb.fit(X_train,y_train)\n",
    "print_score(xgb)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.model_selection import GridSearchCV\\nparameters = [{'n_estimators': [10, 20, 40, 80], 'min_samples_leaf': [3, 5, 7, 10], 'max_features': ['sqrt', 'log2', 0.5]},\\n\\n             ]\\ngrid_search = GridSearchCV(estimator = m,\\n                           param_grid = parameters,\\n                           scoring = 'r2',\\n                           cv = 10,\\n                           n_jobs = -1)\\ngrid_search = grid_search.fit(df, y)\\nbest_accuracy = grid_search.best_score_#given by mean of 10 folds\\nbest_parameters = grid_search.best_params_\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the model after kFold cross validation by using Grid Search\n",
    "\"\"\"from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'n_estimators': [10, 20, 40, 80], 'min_samples_leaf': [3, 5, 7, 10], 'max_features': ['sqrt', 'log2', 0.5]},\n",
    "\n",
    "             ]\n",
    "grid_search = GridSearchCV(estimator = m,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'r2',\n",
    "                           cv = 10,\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search.fit(df, y)\n",
    "best_accuracy = grid_search.best_score_#given by mean of 10 folds\n",
    "best_parameters = grid_search.best_params_\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
